#################################################################
###### FILE MODIFICATO PER LA MACCHINA DEEP
#################################################################
# nome del modello
nomeModello : "Prova128_SN"

#nomeFile per i grafici losses
nomeFileLosses : ["G_losses.csv", "D_losses.csv"]

# Root directory for dataset
dataroot : "~/Focus/Datasets/immagini/celeba"

# Number of workers for dataloader
workers : 3

# Batch size during training
batch_size : 64

# Spatial size of training images. All images will be resized to this
#   size using a transformer.
image_size : 128

# Number of channels in the training images. For color images this is 3
nc : 3

# Size of z latent vector (i.e. size of generator input)
nz : 200

# Size of feature maps in generator
ngf : 128
# Size of feature maps in discriminator
ndf : 128
  
# Number of training epochs
num_epochs : 40

# Learning rate for optimizers
lrd : 0.0002
lrg : 0.0002

# Beta1 hyperparam for Adam optimizers
beta1 : 0.9
beta2 : 0.999

# Number of GPUs available. Se si usa 0 si forza il CPU mode.
ngpu : 1

# Numero di campioni da usare nel debug, se -1 allora si usano tutti i sample nel dataset
n_samples : -1

# Number of layers log_2 (image_size)-3
# k : 2
# calcolato all'interno del programma considerando
# k = int(math.log(image_size, 2)) - 3
